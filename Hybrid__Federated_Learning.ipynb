{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NartoTeroKK/hybrid-federated-learning/blob/main/Hybrid__Federated_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgfV1h-hp9rG"
      },
      "source": [
        "# Configuration and imports\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87q7AODt0Vjf"
      },
      "source": [
        "## Environment installation and conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqUFvs5XDKB8",
        "outputId": "3077e485-0a33-4e9b-d6bc-83864c30625e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Nov 21 14:24 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "# Path and version numbers for python depend on operating system\n",
        "#!which python\n",
        "#!python --version\n",
        "%ls -l\n",
        "# environment variable\n",
        "#%env PYTHONPATH=\n",
        "# install virtual environment package\n",
        "#!pip install virtualenv\n",
        "# create virtual environment\n",
        "#!virtualenv myenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IClHVyRBDf8",
        "outputId": "5583822c-806a-4394-c0fb-37254e423c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flwr\n",
            "  Downloading flwr-1.5.0-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.4/200.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Collecting torch\n",
            "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -U flwr flwr[\"simulation\"] torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6nhmcBHu0w_"
      },
      "source": [
        "## YAML Constants\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f8wS2oUnZcE"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "yaml_config = \"\"\"\n",
        "num_rounds: 3\n",
        "num_partitions: 100\n",
        "batch_size: 4\n",
        "num_classes: 10\n",
        "config_fit:\n",
        "  lr: 0.0004\n",
        "  momentum: 0.9\n",
        "  local_epochs: 1\n",
        "num_cpus: 2\n",
        "num_gpus: 0\n",
        "\"\"\"\n",
        "\n",
        "# Load YAML data into a Python dictionary\n",
        "config = yaml.safe_load(yaml_config)\n",
        "\n",
        "# Access individual configuration values\n",
        "num_rounds = config[\"num_rounds\"]\n",
        "num_partitions = config[\"num_partitions\"]\n",
        "batch_size = config[\"batch_size\"]\n",
        "num_classes = config[\"num_classes\"]\n",
        "config_fit = config[\"config_fit\"]\n",
        "lr = config_fit[\"lr\"]\n",
        "momentum = config_fit[\"momentum\"]\n",
        "local_epochs = config_fit[\"local_epochs\"]\n",
        "num_cpus = config.get(\"num_cpus\", 4)  # You can provide default values\n",
        "num_gpus = config.get(\"num_gpus\", 0.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrSUl_Og1Dz4"
      },
      "source": [
        "# SIMULATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUYKpQDquIko"
      },
      "source": [
        "## Import libs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7U9kcI3vAPl"
      },
      "outputs": [],
      "source": [
        "# General import\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple, Union\n",
        "import timeit\n",
        "# Flower\n",
        "import flwr as fl\n",
        "from flwr.common import (\n",
        "    EvaluateRes,\n",
        "    FitRes,\n",
        "    Scalar\n",
        ")\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.common import Config, NDArrays, Scalar\n",
        "# PyTorch\n",
        "import torch\n",
        "from torch.utils.data import random_split, DataLoader, ConcatDataset, Subset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "# TorchVision\n",
        "from torchvision.datasets import MNIST, utils\n",
        "from torchvision.transforms import ToTensor, Compose, Normalize\n",
        "\n",
        "from logging import DEBUG, INFO\n",
        "from flwr.common.logger import log\n",
        "import timeit\n",
        "from flwr.server.history import History\n",
        "import concurrent.futures\n",
        "from flwr.common import (\n",
        "    Code,\n",
        "    EvaluateIns,\n",
        "    EvaluateRes,\n",
        "    Scalar,\n",
        "    Status,\n",
        "    Parameters\n",
        ")\n",
        "from flwr.common.logger import log\n",
        "\n",
        "FitResultsAndFailures = Tuple[\n",
        "    List[Tuple[ClientProxy, FitRes]],\n",
        "    List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "]\n",
        "\n",
        "EvaluateResultsAndFailures = Tuple[\n",
        "    List[Tuple[ClientProxy, EvaluateRes]],\n",
        "    List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
        "]\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16KpFq601-8r"
      },
      "source": [
        "## Dataset configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDHLo2cY2KvW"
      },
      "source": [
        "### FEMNIST class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSqwfxzC198G"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import MNIST, utils, VisionDataset\n",
        "from torchvision.datasets.utils import check_integrity\n",
        "\n",
        "class FEMNIST(MNIST):\n",
        "    \"\"\"\n",
        "    This dataset is derived from the Leaf repository\n",
        "    (https://github.com/TalwalkarLab/leaf) pre-processing of the Extended MNIST\n",
        "    dataset, grouping examples by writer. Details about Leaf were published in\n",
        "    \"LEAF: A Benchmark for Federated Settings\" https://arxiv.org/abs/1812.01097.\n",
        "    \"\"\"\n",
        "    resources = [\n",
        "        ('https://raw.githubusercontent.com/tao-shen/FEMNIST_pytorch/master/femnist.tar.gz',\n",
        "         '59c65cec646fc57fe92d27d83afdf0ed')]\n",
        "\n",
        "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
        "                 download=False, num_partitions=100):\n",
        "        super(MNIST, self).__init__(root, transform=transform,\n",
        "                                    target_transform=target_transform)\n",
        "        self.train = train\n",
        "\n",
        "        if self._check_legacy_exist():\n",
        "            self.data, self.targets, self.users_index = self.load_data(num_partitions)\n",
        "            return\n",
        "\n",
        "        if download:\n",
        "            self.download()\n",
        "\n",
        "        if not self._check_exists():\n",
        "            raise RuntimeError('Dataset not found.' +\n",
        "                               ' You can use download=True to download it')\n",
        "\n",
        "        self.data, self.targets, self.users_index = self.load_data(num_partitions)\n",
        "\n",
        "\n",
        "    def select_users_data(self, num_partitions):\n",
        "        data = self.data[:num_partitions]\n",
        "        targets = self.targets[:num_partitions]\n",
        "        users_index = self.users_index[:num_partitions]\n",
        "\n",
        "        return data, targets, users_index\n",
        "\n",
        "\n",
        "    def load_data(self, num_partitions):\n",
        "\n",
        "        if self.train:\n",
        "            data_file = self.training_file\n",
        "        else:\n",
        "            data_file = self.test_file\n",
        "\n",
        "        return torch.load(os.path.join(self.processed_folder, data_file))\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = self.data[index], int(self.targets[index])\n",
        "        img = Image.fromarray(img.numpy(), mode='F')\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.target_transform is not None:\n",
        "            target = self.target_transform(target)\n",
        "        return img, target\n",
        "\n",
        "    def download(self):\n",
        "        \"\"\"Download the FEMNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
        "        import shutil\n",
        "        def makedir_exist_ok(dirpath):\n",
        "            import errno\n",
        "            \"\"\"\n",
        "            Python2 support for os.makedirs(.., exist_ok=True)\n",
        "            \"\"\"\n",
        "            try:\n",
        "                os.makedirs(dirpath)\n",
        "            except OSError as e:\n",
        "                if e.errno == errno.EEXIST:\n",
        "                    pass\n",
        "                else:\n",
        "                    raise\n",
        "\n",
        "        if self._check_exists():\n",
        "            return\n",
        "\n",
        "        makedir_exist_ok(self.raw_folder)\n",
        "        makedir_exist_ok(self.processed_folder)\n",
        "\n",
        "        # download files\n",
        "        print('Downloading and extracting ...')\n",
        "        for url, md5 in self.resources:\n",
        "            filename = url.rpartition('/')[2]\n",
        "            utils.download_and_extract_archive(url, download_root=self.raw_folder, extract_root=self.processed_folder, filename=filename, md5=md5)\n",
        "\n",
        "    def _check_exists(self) -> bool:\n",
        "        return all(\n",
        "            check_integrity(os.path.join( self.raw_folder, os.path.basename(url) ))\n",
        "            for url, _ in self.resources\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaswOKr72Mbf"
      },
      "source": [
        "### Prepare dataset and loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DstEL9TV1ykp"
      },
      "outputs": [],
      "source": [
        "def get_femnist(data_path: str='./data'):\n",
        "\n",
        "    transform = Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "    trainset = FEMNIST(root=data_path, train=True, download=True, transform=transform, num_partitions=num_partitions)\n",
        "    testset = FEMNIST(root=data_path, train=False, download=True, transform=transform, num_partitions=num_partitions)\n",
        "\n",
        "    print(len(trainset.data), len(testset.data))\n",
        "    #print(trainset.data.shape,'\\n', trainset.data.size,'\\n', trainset.data[0].shape)\n",
        "    #print(trainset.targets.shape,'\\n', trainset.targets.size,'\\n', trainset.targets[0].shape)\n",
        "\n",
        "    return trainset, testset\n",
        "\n",
        "def split_user_datatset(dataset, num_partitions):\n",
        "    datasets = []\n",
        "    images_taken = 0\n",
        "\n",
        "    for i in range(num_partitions):\n",
        "        num_images = dataset.users_index[i]\n",
        "        datasets.append(Subset(dataset, range(images_taken, images_taken + num_images)))\n",
        "        images_taken += num_images\n",
        "\n",
        "    return datasets\n",
        "\n",
        "\n",
        "def merge_datasets(trainsets, testsets):\n",
        "    import random\n",
        "\n",
        "    merged_trainsets = []\n",
        "    merged_testset = []\n",
        "    if len(trainsets) == len(testsets):\n",
        "        rand_indexes = random.sample(range(0, len(trainsets)), X)\n",
        "        rand_indexes.sort()\n",
        "    else:\n",
        "        raise Exception(\"trainsets and testsets must have the same length\")\n",
        "    print(rand_indexes)\n",
        "\n",
        "    for i in rand_indexes:\n",
        "        merged_trainsets.append(trainsets[i])\n",
        "        trainsets[i] = None\n",
        "        merged_testset.append(testsets[i])\n",
        "        testsets[i] = None\n",
        "\n",
        "\n",
        "    trainsets = [x for x in trainsets if x is not None]\n",
        "    testsets = [x for x in testsets if x is not None]\n",
        "\n",
        "    trainsets.append(ConcatDataset(merged_trainsets))\n",
        "    testsets.append(ConcatDataset(merged_testset))\n",
        "\n",
        "    return trainsets, testsets\n",
        "\n",
        "def prepare_dataset(num_partitions: int, batch_size: int, val_ratio: float = 0.1):\n",
        "\n",
        "    trainset, testset = get_femnist()\n",
        "\n",
        "    trainsets = split_user_datatset(trainset, num_partitions)\n",
        "    testsets = split_user_datatset(testset, num_partitions)\n",
        "\n",
        "    if X > 0:\n",
        "        trainsets, testsets = merge_datasets(trainsets, testsets)\n",
        "\n",
        "    # Create dataloaders with train+val support\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "\n",
        "    for trainset_ in trainsets:\n",
        "        num_total = len(trainset_)\n",
        "        num_val = int(num_total * val_ratio)\n",
        "        num_train = num_total - num_val\n",
        "\n",
        "        for_train, for_val = random_split(trainset_, [num_train, num_val], generator=torch.Generator().manual_seed(2023))\n",
        "        del trainset_\n",
        "\n",
        "        trainloaders.append(DataLoader(for_train, batch_size=batch_size, shuffle=True, num_workers=2))\n",
        "        valloaders.append(DataLoader(for_val, batch_size=batch_size, shuffle=False, num_workers=2))\n",
        "\n",
        "    testloaders = []\n",
        "\n",
        "    for testset in testsets:\n",
        "        testloaders.append(DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2))\n",
        "\n",
        "    del testsets, trainsets, trainset, testset\n",
        "\n",
        "    return trainloaders, valloaders, testloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Mjb4xfM3iSs"
      },
      "source": [
        "## Network MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CTgF98W3m1V"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes: int) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv2d_1 = nn.Conv2d(1, 32, kernel_size=3)\n",
        "        self.max_pooling = nn.MaxPool2d(2, stride=2)\n",
        "        self.conv2d_2 = nn.Conv2d(32, 64, kernel_size=3)\n",
        "        self.dropout_1 = nn.Dropout(0.25)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_1 = nn.Linear(9216, 128)\n",
        "        self.dropout_2 = nn.Dropout(0.5)\n",
        "        self.linear_2 = nn.Linear(128, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "        #self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv2d_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2d_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.max_pooling(x)\n",
        "        x = self.dropout_1(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout_2(x)\n",
        "        x = self.linear_2(x)\n",
        "        #x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "    '''\n",
        "        def __init__(self, num_classes: int) -> None:\n",
        "            super(Net, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "            self.pool = nn.MaxPool2d(2, 2)\n",
        "            self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "            self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "            self.fc2 = nn.Linear(120, 84)\n",
        "            self.fc3 = nn.Linear(84, num_classes)\n",
        "\n",
        "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "            x = self.pool(F.relu(self.conv1(x)))\n",
        "            x = self.pool(F.relu(self.conv2(x)))\n",
        "            x = x.view(-1, 16 * 4 * 4)\n",
        "            x = F.relu(self.fc1(x))\n",
        "            x = F.relu(self.fc2(x))\n",
        "            x = self.fc3(x)\n",
        "            return x\n",
        "    '''\n",
        "\n",
        "def train(net, trainloader, optimizer, epochs, device: str):\n",
        "    \"\"\"Train the network on the training set.\n",
        "\n",
        "    This is a fairly simple training loop for PyTorch.\n",
        "    \"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
        "    net.train()\n",
        "    net.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        total, correct, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss.item()\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        #print(f\"accuracy {epoch_acc}\")\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def test(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set.\n",
        "    and report loss and accuracy.\n",
        "    \"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    net.to(device)\n",
        "    y_true, y_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = correct / total\n",
        "    f_score = f1_score(y_true, y_pred, average='weighted')\n",
        "    return loss, accuracy, f_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PuY57i6NOb5"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoUhDWkFNVs8"
      },
      "outputs": [],
      "source": [
        "def get_client_parameters(cid):\n",
        "        params_array = np.load(\"parameters.npy\", allow_pickle=True)\n",
        "        params = params_array[int(cid)]\n",
        "        del params_array\n",
        "\n",
        "        return parameters_to_ndarrays(params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkE9rjMm45-a"
      },
      "source": [
        "## Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owfP2Bn05BEd"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self,\n",
        "                 cid: str,\n",
        "                 trainloader,\n",
        "                 valloader,\n",
        "                 testloader,\n",
        "                 num_classes) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.cid = cid\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.testloader = testloader\n",
        "\n",
        "        self.model = Net(num_classes)\n",
        "\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar]):\n",
        "\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "\n",
        "        server_round = config['server_round']\n",
        "        # copy parameter sent by the server into client's local model\n",
        "        '''\n",
        "        if server_round == 1:\n",
        "            self.set_parameters(self.get_parameters({}))\n",
        "        else:\n",
        "            self.set_parameters(get_client_parameters(self.cid))\n",
        "        '''\n",
        "\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        lr = config['lr']\n",
        "        momentum = config['momentum']\n",
        "        epochs = config['local_epochs']\n",
        "\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "        # do local training\n",
        "        #print(\"Client CID: \", self.cid, \" - trainset length: \", len(self.trainloader.dataset))\n",
        "        train(self.model, self.trainloader, optimizer, epochs, self.device)\n",
        "\n",
        "        #self.set_parameters(self.get_parameters({}))\n",
        "\n",
        "        return self.get_parameters({}), len(self.trainloader), {}\n",
        "        #int(self.cid)\n",
        "\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        server_round = config['server_round']\n",
        "\n",
        "        #self.set_parameters(get_client_parameters(self.cid))\n",
        "        self.set_parameters(parameters)\n",
        "\n",
        "        if server_round == config['num_rounds']:\n",
        "\n",
        "            #print(\"Client CID: \", self.cid, \" - testset length: \", len(self.testloader.dataset))\n",
        "            loss, accuracy, f_score = test(self.model, self.testloader, self.device)\n",
        "            #print(\"FINAL ACCURACY: \", accuracy)\n",
        "\n",
        "            return float(loss), len(self.testloader), {'accuracy': accuracy, 'f-score': f_score}\n",
        "        else:\n",
        "\n",
        "            #print(\"Client CID: \", self.cid, \" - testset length: \", len(self.valloader.dataset))\n",
        "            loss, accuracy, f_score = test(self.model, self.valloader, self.device)\n",
        "            #print(\"accuracy: \", accuracy)\n",
        "\n",
        "            return float(loss), len(self.valloader), {'accuracy': accuracy, 'f-score': f_score}\n",
        "\n",
        "\n",
        "def generate_client_fn(trainloaders, valloaders, testloaders, num_classes):\n",
        "\n",
        "    def client_fn(cid: str):\n",
        "        return FlowerClient(cid=cid,\n",
        "                            trainloader=trainloaders[int(cid)],\n",
        "                            valloader=valloaders[int(cid)],\n",
        "                            testloader=testloaders[int(cid)],\n",
        "                            num_classes=num_classes)\n",
        "    return client_fn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhugEqc46EkA"
      },
      "source": [
        "## Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6WZn29r6Jir"
      },
      "outputs": [],
      "source": [
        "def get_on_fit_config_fn(config: dict):\n",
        "\n",
        "    def fit_config_fn(server_round: int):\n",
        "\n",
        "        return {'lr': config[\"lr\"], 'momentum': config[\"momentum\"],\n",
        "                'local_epochs': config[\"local_epochs\"], 'server_round': server_round}\n",
        "\n",
        "    return fit_config_fn\n",
        "\n",
        "def get_on_evaluate_config_fn(config):\n",
        "\n",
        "    def evaluate_config_fn(server_round: int):\n",
        "\n",
        "        if server_round == config['num_rounds']:\n",
        "            print('______ FINAL EVALUATE _____')\n",
        "\n",
        "        return {'num_rounds': config['num_rounds'], 'server_round': server_round}\n",
        "\n",
        "    return evaluate_config_fn\n",
        "\n",
        "\n",
        "def get_evaluate_fn(num_classes: int, testloader):\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "\n",
        "        model = Net(num_classes)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        loss, accuracy = test(model, testloader, device)\n",
        "\n",
        "        return loss, {'accuracy': accuracy}\n",
        "\n",
        "    return evaluate_fn\n",
        "\n",
        "\n",
        "from logging import WARNING\n",
        "from flwr.common import (\n",
        "    ndarrays_to_parameters,\n",
        "    Parameters,\n",
        "    parameters_to_ndarrays)\n",
        "from flwr.server.strategy.aggregate import aggregate\n",
        "\n",
        "\n",
        "class AggregateCustomMetricStrategy(fl.server.strategy.FedAvg):\n",
        "    def aggregate_evaluate(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate evaluation accuracy using weighted average.\"\"\"\n",
        "\n",
        "        if not results:\n",
        "            return None, {}\n",
        "\n",
        "        # Call aggregate_evaluate from base class (FedAvg) to aggregate loss and metrics\n",
        "        aggregated_loss, aggregated_metrics = super().aggregate_evaluate(server_round, results, failures)\n",
        "\n",
        "        # Weigh accuracy of each client by number of examples used\n",
        "        accuracies = [r.metrics[\"accuracy\"] * r.num_examples for _, r in results]\n",
        "        f_scores = [r.metrics[\"f-score\"] * r.num_examples for _, r in results]\n",
        "        examples = [r.num_examples for _, r in results]\n",
        "\n",
        "        print(\"accuracies: \",accuracies,\"examples: \",examples)\n",
        "\n",
        "        # Aggregate and print custom metric\n",
        "        aggregated_accuracy = sum(accuracies) / sum(examples)\n",
        "        aggregated_f_score = sum(f_scores) / sum(examples)\n",
        "        print(f\"Round {server_round} accuracy aggregated from client results: {aggregated_accuracy}\")\n",
        "        print(f\"Round {server_round} f-score aggregated from client results: {aggregated_f_score}\")\n",
        "\n",
        "        # Return aggregated loss and metrics (i.e., aggregated accuracy)\n",
        "        return aggregated_loss, {\"accuracy\": aggregated_accuracy, \"f-score\": aggregated_f_score}\n",
        "\n",
        "    '''\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[ClientProxy, FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Dict[str, Scalar]:\n",
        "        \"\"\"Aggregate fit results using weighted average.\"\"\"\n",
        "        if not results:\n",
        "            return {}\n",
        "        # Do not aggregate if there are failures and failures are not accepted\n",
        "        if not self.accept_failures and failures:\n",
        "            return {}\n",
        "\n",
        "\n",
        "        # Aggregate custom metrics if aggregation fn was provided\n",
        "        metrics_aggregated = {}\n",
        "        if self.fit_metrics_aggregation_fn:\n",
        "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
        "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
        "        elif server_round == 1:  # Only log this warning once\n",
        "            log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
        "\n",
        "        return metrics_aggregated\n",
        "    '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdBdWR-i9r1z"
      },
      "source": [
        "## Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-jGjjsx9uA7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "from flwr.server.server import fit_clients\n",
        "\n",
        "class MyServer(fl.server.Server):\n",
        "\n",
        "    # pylint: disable=too-many-locals\n",
        "    def fit(self, num_rounds: int, timeout: Optional[float]) -> History:\n",
        "        \"\"\"Run federated averaging for a number of rounds.\"\"\"\n",
        "        history = History()\n",
        "\n",
        "        # Initialize parameters\n",
        "        log(INFO, \"Initializing global parameters\")\n",
        "        self.parameters = Parameters(\n",
        "            tensors=[], tensor_type=\"numpy.ndarray\"\n",
        "        )\n",
        "        log(INFO, \"Evaluating initial parameters\")\n",
        "        res = self.strategy.evaluate(0, parameters=self.parameters)\n",
        "        if res is not None:\n",
        "            log(\n",
        "                INFO,\n",
        "                \"initial parameters (loss, other metrics): %s, %s\",\n",
        "                res[0],\n",
        "                res[1],\n",
        "            )\n",
        "            history.add_loss_centralized(server_round=0, loss=res[0])\n",
        "            history.add_metrics_centralized(server_round=0, metrics=res[1])\n",
        "\n",
        "        # Run federated learning for num_rounds\n",
        "        log(INFO, \"FL starting\")\n",
        "        start_time = timeit.default_timer()\n",
        "\n",
        "        for current_round in range(1, num_rounds + 1):\n",
        "            # Train model and replace previous global model\n",
        "            res_fit = self.fit_round(\n",
        "                server_round=current_round,\n",
        "                timeout=timeout,\n",
        "            )\n",
        "            if res_fit is not None:\n",
        "                fit_metrics, _ = res_fit  # fit_metrics_aggregated\n",
        "\n",
        "                history.add_metrics_distributed_fit(\n",
        "                    server_round=current_round, metrics=fit_metrics\n",
        "                )\n",
        "\n",
        "            # Evaluate model on a sample of available clients\n",
        "            res_fed = self.evaluate_round(server_round=current_round, timeout=timeout)\n",
        "            print(\"results federated: \", res_fed)\n",
        "            if res_fed is not None:\n",
        "                loss_fed, evaluate_metrics_fed, _ = res_fed\n",
        "                if loss_fed is not None:\n",
        "                    history.add_loss_distributed(\n",
        "                        server_round=current_round, loss=loss_fed\n",
        "                    )\n",
        "                    history.add_metrics_distributed(\n",
        "                        server_round=current_round, metrics=evaluate_metrics_fed\n",
        "                    )\n",
        "\n",
        "        # Bookkeeping\n",
        "        end_time = timeit.default_timer()\n",
        "        elapsed = end_time - start_time\n",
        "        log(INFO, \"FL finished in %s\", elapsed)\n",
        "        return history\n",
        "\n",
        "    def fit_round(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        timeout: Optional[float],\n",
        "    ) -> Optional[\n",
        "        Tuple[Dict[str, Scalar], FitResultsAndFailures]\n",
        "    ]:\n",
        "        \"\"\"Perform a single round of federated averaging.\"\"\"\n",
        "        # Get clients and their respective instructions from strategy\n",
        "        client_instructions = self.strategy.configure_fit(\n",
        "            server_round=server_round,\n",
        "            parameters=self.parameters,\n",
        "            client_manager=self._client_manager,\n",
        "        )\n",
        "\n",
        "        if not client_instructions:\n",
        "            log(INFO, \"fit_round %s: no clients selected, cancel\", server_round)\n",
        "            return None\n",
        "        log(\n",
        "            DEBUG,\n",
        "            \"fit_round %s: strategy sampled %s clients (out of %s)\",\n",
        "            server_round,\n",
        "            len(client_instructions),\n",
        "            self._client_manager.num_available(),\n",
        "        )\n",
        "\n",
        "        # Collect `fit` results from all clients participating in this round\n",
        "        results, failures = fit_clients(\n",
        "            client_instructions=client_instructions,\n",
        "            max_workers=self.max_workers,\n",
        "            timeout=timeout,\n",
        "        )\n",
        "        log(\n",
        "            DEBUG,\n",
        "            \"fit_round %s received %s results and %s failures\",\n",
        "            server_round,\n",
        "            len(results),\n",
        "            len(failures),\n",
        "        )\n",
        "\n",
        "        params_array = np.load(\"parameters.npy\", allow_pickle=True)\n",
        "        for _, res in results:\n",
        "            cid = res.num_examples\n",
        "            #print(\"cid: \", cid, \"len parameters: \", len(res.parameters.tensors))\n",
        "            params_array[cid] = res.parameters\n",
        "        np.save(\"parameters.npy\", params_array)\n",
        "\n",
        "        # Aggregate training results\n",
        "        aggregated_result: Tuple[\n",
        "            Dict[str, Scalar],\n",
        "        ] = self.strategy.aggregate_fit(server_round, results, failures)\n",
        "\n",
        "        metrics_aggregated = aggregated_result\n",
        "        return metrics_aggregated, (results, failures)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVBOQ61BvAoM"
      },
      "source": [
        "# Main\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpaYc3BaqUri"
      },
      "outputs": [],
      "source": [
        "#for X in [80, 60, 40, 20, 0]:\n",
        "#for num_rounds in [3,5]:\n",
        "for iteration in range(4):\n",
        "    X = 0\n",
        "    ## num of FL and Centralized clients configured\n",
        "    if X <= 1: X = 0\n",
        "    if X > num_partitions: X = num_partitions\n",
        "\n",
        "    num_clients = num_partitions\n",
        "    if X > 0: num_clients = num_clients - X + 1\n",
        "\n",
        "    print(\"--- ITERATION n. \",iteration + 1,\" ---\\n\")\n",
        "\n",
        "    # Print the configuration\n",
        "    print(\"num_rounds:\", num_rounds)\n",
        "    print(\"num_partitions:\", num_partitions)\n",
        "    '''\n",
        "    print(\"batch_size:\", batch_size)\n",
        "    print(\"num_classes:\", num_classes)\n",
        "    print(\"config_fit:\")\n",
        "    print(\"   lr:\", lr)\n",
        "    print(\"   momentum:\", momentum)\n",
        "    print(\"   local_epochs:\", local_epochs)\n",
        "    print(\"num_cpus:\", num_cpus)\n",
        "    print(\"num_gpus:\", num_gpus)\n",
        "    '''\n",
        "    print(\"____________________\")\n",
        "    print(\"\\nX:\", X)\n",
        "    print(\"num_clients: \", num_clients)\n",
        "    print(\"____________________\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Training on {device} using PyTorch {torch.__version__} and Flower {fl.__version__}\\n\")\n",
        "\n",
        "    ## 2. Prepare dataset\n",
        "    trainloaders, validationloaders, testloaders = prepare_dataset(num_partitions, batch_size)\n",
        "    print(\"FEMNIST Dataset prepared\\n\")\n",
        "\n",
        "    ## 3. Define clients\n",
        "    client_fn = generate_client_fn(trainloaders, validationloaders, testloaders, num_classes)\n",
        "\n",
        "    ## 4. Define strategy\n",
        "    strategy =  AggregateCustomMetricStrategy(  # fl.server.strategy.FedAvg\n",
        "        min_fit_clients=num_clients,\n",
        "        min_evaluate_clients=num_clients,\n",
        "        min_available_clients=num_clients,\n",
        "        on_fit_config_fn=get_on_fit_config_fn(config_fit),\n",
        "        evaluate_fn=None,   # get_evaluate_fn(num_classes, testloader)\n",
        "        on_evaluate_config_fn=get_on_evaluate_config_fn(config),\n",
        "        accept_failures=False,\n",
        "    )\n",
        "\n",
        "    start = timeit.default_timer()\n",
        "    ## 5. Start Simulation\n",
        "    history = fl.simulation.start_simulation(\n",
        "        client_fn=client_fn,\n",
        "        num_clients=num_clients,\n",
        "        config=fl.server.ServerConfig(num_rounds=num_rounds),\n",
        "        strategy=strategy,\n",
        "        client_resources={'num_cpus': num_cpus, 'num_gpus': num_gpus},\n",
        "        #server=MyServer(client_manager=fl.server.client_manager.SimpleClientManager(), strategy=strategy)\n",
        "    )\n",
        "    end = timeit.default_timer()\n",
        "    elapsed = end - start\n",
        "    print(\"SIMULATION TIME: \",elapsed,\" s\")\n",
        "    ## 6. Save your results\n",
        "    import datetime\n",
        "\n",
        "    output_dir = \"/content/outputs/\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    # Get the current date and time\n",
        "    now = datetime.datetime.now()\n",
        "    formatted_date = now.strftime(\"%Y-%m-%d_%H-%M-%S\")  # Format the date and time as desired\n",
        "\n",
        "    filename = f\"result_{formatted_date}_{device}_X{X}.txt\"\n",
        "    results_path = output_dir + filename\n",
        "    results_content = f\"Config:{yaml_config}\\nX: {X}\\nnum_clients: {num_clients}\\n\\nSimulation time: {elapsed}\\nHistory:\\n{history}\\n\"\n",
        "    # Save the content to the file\n",
        "    with open(results_path, 'w') as file:\n",
        "        file.write(results_content)\n",
        "    print(\"results file created.\")\n",
        "\n",
        "    # Optionally, you can download the saved file to your local machine\n",
        "    from google.colab import files\n",
        "    files.download(results_path)\n",
        "    print(\"results file downloaded.\")\n",
        "    print(\"---------------------------------------------------------\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPoglLhA+ov4ddDpRC0KwQm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}